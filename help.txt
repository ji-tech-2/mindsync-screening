MENTAL WELLNESS MODEL MICROSERVICE - TECHNICAL DOCUMENTATION

1. SYSTEM OVERVIEW
------------------
This microservice is a Flask-based application that serves a pre-trained Machine Learning pipeline. The core model is a custom implementation of Ridge Regression (LinearRegressionRidge) integrated with a Scikit-Learn pipeline that handles feature standardization automatically.

The system is designed to run within a Docker container to ensure environment consistency across development and production.

2. ARCHITECTURE & FILE STRUCTURE
--------------------------------
model_service/
  |-- artifacts/
      |-- model.pkl        : The serialized model pipeline (Pickle format).
  |-- app.py               : Main application entry point. Contains the API logic and the custom model class definition.
  |-- Dockerfile           : Configuration for building the lightweight Linux-based container.
  |-- requirements.txt     : List of Python dependencies.
  |-- test_api.py          : Utility script to verify API health and prediction accuracy.

3. MODEL IMPLEMENTATION DETAILS
-------------------------------
The model is not a standard Scikit-Learn object but a custom class named 'LinearRegressionRidge'. 

Important Note on Serialization:
Because the model uses a custom class structure, the class definition for 'LinearRegressionRidge' is explicitly included in 'app.py'. This is required for the Python 'pickle' module to successfully reconstruct the model object during the load process. Do not remove or modify this class definition in 'app.py' without also retraining and re-serializing the model artifact.

Preprocessing:
The loaded pipeline contains a StandardScaler step. The API expects raw numerical and categorical inputs; scaling is applied internally before prediction.

4. API SPECIFICATION
--------------------
Base URL: http://localhost:5000

Endpoint: /predict
Method: POST
Content-Type: application/json

Request Schema:
The API accepts a JSON object (single record) or a list of JSON objects (batch).
Required fields:
- age (int/float)
- gender (string)
- occupation (string)
- work_mode (string)
- screen_time_hours (float)
- work_screen_hours (float)
- leisure_screen_hours (float)
- sleep_hours (float)
- sleep_quality_1_5 (int: 1-5)
- stress_level_0_10 (float: 0-10)
- productivity_0_100 (float: 0-100)
- exercise_minutes_per_week (int)
- social_hours_per_week (float)

Response Schema:
{
  "prediction": [45.2, ...],
  "status": "success"
}

Error Handling:
If the input JSON is missing columns or contains invalid data types, the API will return a 400 or 500 status code with a JSON error message describing the issue.

5. DEPLOYMENT & CONFIGURATION
-----------------------------
Port Configuration:
The application is hardcoded to listen on port 5000 in 'app.py'. The Dockerfile exposes port 5000 to match this configuration.

Production Server:
The Dockerfile uses Gunicorn as the WSGI HTTP server for production stability. It is configured to bind to 0.0.0.0:5000.

Environment Variables:
- PYTHONDONTWRITEBYTECODE=1: Prevents Python from writing .pyc files.
- PYTHONUNBUFFERED=1: Ensures application logs are flushed to the container output immediately.

6. MAINTENANCE
--------------
Updating the Model:
1. Retrain the model in your experimentation environment.
2. Save the new artifact as 'model.pkl'.
3. Replace 'model_service/artifacts/model.pkl' with the new file.
4. Rebuild the Docker image using 'docker build'.

Updating Dependencies:
If new libraries are required (e.g., if the model architecture changes), update 'requirements.txt' and rebuild the Docker image. Keep the dependency list minimal to maintain a small image size.